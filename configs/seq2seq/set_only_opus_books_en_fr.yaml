task: seq2seq

model:
  family: encoder_set_only
  vocab_size: 0
  d_model: 256
  num_layers: 4
  num_heads: 8
  window_size: 32
  stride: 16
  dropout: 0.1
  max_seq_len: 256
  backend: dense_exact
  router_topk: 4
  feature_mode: hashed_counts
  router_type: learned
  pooling:
    mode: mean
  geometry:
    enabled: true
    apply_as_bias: false
    apply_in_phi_attn: true
  sig_gating:
    enabled: false
  seq2seq:
    shared_vocab: true

data:
  seq_dataset: opus_books_en_fr
  batch_size: 16
  seq_len: 256

training:
  epochs: 5
  lr: 0.0003
  seed: 0
