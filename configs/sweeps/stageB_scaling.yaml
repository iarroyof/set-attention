# =============================================================================
# Stage B: Scaling Analysis (Memory & Throughput)
# =============================================================================
# Purpose: Demonstrate O(n²) baseline vs O(n) SKA memory scaling
# Expected runs: 2 W&B runs (internal iteration over lengths)
# Estimated time: ~2-4 hours on 2× RTX-4090
# Key insight: Baseline will OOM at ~2048-4096 tokens, SKA continues to 8192+
# =============================================================================

program: scripts/run_stageB_sweeps.py

parameters:
  # ============================================
  # Output & Logging
  # ============================================
  output-dir:
    value: out/production/stageB
  cache-mode:
    value: full
  stageb-mode:
    value: train  # Not just benchmark
  epochs:
     value: 3
  production:
    value: true
  wandb-project:
    value: set-attention-stageB
  # Reduced logging frequency for efficiency benchmarks
  grad-log-interval:
    value: 10

  # ============================================
  # Task Selection (Scaling-relevant tasks only)
  # ============================================
  # ViT excluded: CIFAR-10 is fixed 32×32, no sequence length scaling
  # Seq2Seq excluded: encoder+decoder complicates memory analysis
  tasks:
    value: [lm, textdiff]

  # ============================================
  # SWEEP AXIS: Model Type
  # ============================================
  model-type:
    values: [baseline, ska]

  # ============================================
  # Fixed Model Settings
  # ============================================
  baseline-impl:
    value: explicit
  ska-backend:
    value: python
  # Fixed to best kernel from Stage A (or delta_plus_dot as default)
  ska-score-mode:
    value: delta_plus_dot

  # ============================================
  # LM (WikiText-103) - Aggressive Scaling Sweep
  # ============================================
  lm-dataset:
    value: wikitext103
  lm-subset-path:
    value: subsets/wikitext103_train_10pct.json
  lm-precision:
    value: fp16
  # REDUCED batch size to push sequence lengths higher before OOM
  lm-batch:
    value: 8
  # AGGRESSIVE length sweep: baseline will OOM around 2048-4096
  lm-lengths:
    values: [512, 1024, 2048, 4096, 8192]
  lm-seq-stride:
    value: 0
  # SKA hyperparameters
  lm-window:
    value: 64
  lm-stride:
    value: 32
  lm-minhash-k:
    value: 128
  lm-router-topk:
    value: 4

  # ============================================
  # Seq2Seq (WMT16 EN-RO) - Not run in this sweep
  # ============================================
  # Keeping config for completeness; not executed due to tasks=[lm, textdiff]
  seq-dataset:
    value: wmt16_en_ro
  seq-subset-path:
    value: subsets/wmt16_en_ro_train_10pct.json
  seq-precision:
    value: fp16
  seq-batch:
    value: 4
  seq-lengths:
    values: [128, 256, 512, 1024]
  seq-max-len:
    value: 256
  seq-tokenizer-type:
    value: whitespace
  seq-window:
    value: 64
  seq-stride:
    value: 32
  seq-minhash-k:
    value: 128
  seq-router-topk:
    value: 4

  # ============================================
  # TextDiff (WikiText-103) - Scaling Sweep
  # ============================================
  textdiff-dataset:
    value: wikitext103
  textdiff-subset-path:
    value: subsets/wikitext103_train_10pct.json
  textdiff-precision:
    value: fp16
  # REDUCED batch size for longer sequences
  textdiff-batch:
    value: 8
  # Scaling sweep for diffusion
  textdiff-lengths:
    values: [256, 512, 1024, 2048]
  textdiff-seq-len:
    value: 256
  textdiff-stride:
    value: 256
  # SKA hyperparameters
  textdiff-window:
    value: 64
  textdiff-bank-stride:
    value: 32
  textdiff-minhash-k:
    value: 128
  textdiff-router-topk:
    value: 4

  # ============================================
  # ViT (CIFAR-10) - Not run in this sweep
  # ============================================
  # Keeping config for completeness; not executed due to tasks=[lm, textdiff]
  vit-precision:
    value: fp16
  vit-batch:
    value: 128
  vit-subset-path:
    value: ""
  vit-window:
    value: 8
  vit-stride:
    value: 4
  vit-minhash-k:
    value: 64
  vit-router-topk:
    value: 0