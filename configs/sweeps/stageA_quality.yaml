# =============================================================================
# Stage A: Quality Comparison (Full Kernel Ablation)
# =============================================================================
# Purpose: Compare baseline vs SKA quality across all score modes
# Expected runs: 20 W&B runs (12 unique configs after baseline dedup)
# Estimated time: ~6-8 hours on 2Ã— RTX-4090
# =============================================================================

program: scripts/run_stageA_sweeps.py

parameters:
  # ============================================
  # Output & Logging
  # ============================================
  output-dir:
    value: out/production/stageA
  cache-mode:
    value: full
  epochs:
    value: 15
  production:
    value: true
  wandb-project:
    value: set-attention-stageA

  # ============================================
  # SWEEP AXES (Full Factorial)
  # ============================================
  
  # Core comparison: baseline vs SKA
  model-type:
    values: [baseline, ska]
  
  # Kernel ablation: all 5 score modes
  # NOTE: baseline runs ignore this (creates redundant runs, dedupe in analysis)
  ska-score-mode:
    values: [dot, delta_rbf, delta_plus_dot, intersect_norm, intersect_plus_dot]

  # ============================================
  # Fixed Model Settings
  # ============================================
  baseline-impl:
    value: explicit
  ska-backend:
    value: python

  # ============================================
  # LM (WikiText-103) - Quality Focus
  # ============================================
  lm-dataset:
    value: wikitext103
  lm-subset-path:
    value: subsets/wikitext103_train_10pct.json
  lm-precision:
    value: fp32
  lm-batch:
    value: 8
  # Sweep sequence length for richer quality data
  lm-seq-len:
    value: 256
  lm-seq-stride:
    value: 0
  # SKA hyperparameters (fixed - not ablating these in Stage A)
  lm-window:
    value: 64
  lm-stride:
    value: 32
  lm-minhash-k:
    value: 128
  lm-router-topk:
    value: 4

  # ============================================
  # Seq2Seq (WMT16 EN-RO) - Quality Focus
  # ============================================
  seq-dataset:
    value: wmt16_en_ro
  seq-subset-path:
    value: subsets/wmt16_en_ro_train_10pct.json
  seq-precision:
    value: fp32
  seq-batch:
    value: 8
  seq-max-len:
    value: 256
  seq-tokenizer-type:
    value: whitespace
  # SKA hyperparameters
  seq-window:
    value: 64
  seq-stride:
    value: 32
  seq-minhash-k:
    value: 128
  seq-router-topk:
    value: 4

  # ============================================
  # TextDiff (WikiText-103) - Quality Focus
  # ============================================
  textdiff-dataset:
    value: wikitext103
  textdiff-subset-path:
    value: subsets/wikitext103_train_10pct.json
  textdiff-precision:
    value: fp32
  textdiff-batch:
    value: 8
  textdiff-seq-len:
    value: 256
  textdiff-stride:
    value: 256
  # SKA hyperparameters
  textdiff-window:
    value: 64
  textdiff-bank-stride:
    value: 32
  textdiff-minhash-k:
    value: 128
  textdiff-router-topk:
    value: 4

  # ============================================
  # ViT (CIFAR-10) - Quality Focus
  # ============================================
  vit-precision:
    value: fp32
  vit-batch:
    value: 8
  vit-subset-path:
    value: ""
  # SKA hyperparameters
  vit-window:
    value: 8
  vit-stride:
    value: 4
  vit-minhash-k:
    value: 64
  vit-router-topk:
    value: 0