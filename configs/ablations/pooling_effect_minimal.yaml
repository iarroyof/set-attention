model:
  family: set_only
  vocab_size: 0
  d_model: 256
  num_layers: 4
  num_heads: 8
  window_size: 32
  stride: 16
  dropout: 0.1
  max_seq_len: 256
  backend: dense_exact
  router_topk: 4
  feature_mode: hashed_counts
  router_type: learned
  pooling:
    mode: mean
  geometry:
    enabled: true
    apply_as_bias: false
    apply_in_phi_attn: true
  sig_gating:
    enabled: false
training:
  epochs: 5
  lr: 0.0003
  seed: 0
data:
  dataset: wikitext2
  limit: 50
  batch_size: 16
  seq_len: 256
