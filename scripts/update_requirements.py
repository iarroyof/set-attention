#!/usr/bin/env python
"""
Update requirements.txt, requirements-experiments.txt and requirements-dev.txt
from the currently active Python environment.

Usage (from repo root):

    conda activate triton
    python scripts/update_requirements.py

If you add new dependencies to the project, just add the package name
to the appropriate *_PKGS list below and re-run this script.
"""

from __future__ import annotations

import importlib.metadata as md
from pathlib import Path

# --- Package sets to track and pin -----------------------------------------

# Core runtime / library deps
RUNTIME_PKGS = [
    "torch",
    "triton",
    "einops",
    "numpy",
    "typing-extensions",
    "networkx",
    "fsspec",
    "jinja2",
    "filelock",
    "sympy",
]

# Extra deps for training / experiments
EXPERIMENT_PKGS = [
    "datasets",
    "tqdm",
    "pandas",
    "pyarrow",
    "pillow",
    "huggingface-hub",
    "hf-xet",
    "requests",
    "pyyaml",
    "python-dateutil",
    "pytz",
    "tzdata",
]

# Dev-only tooling; any that are missing will simply be skipped
DEV_PKGS = [
    "ipython",
    "pipreqs",
    # "pytest",
    # "black",
    # "isort",
]


# --- Helpers ----------------------------------------------------------------


def get_version(pkg: str) -> str | None:
    """Return installed version string or None if not installed."""
    try:
        return md.version(pkg)
    except md.PackageNotFoundError:
        return None


def format_lines(pkg_names: list[str]) -> list[str]:
    """Return ['name==version', ...] for installed packages."""
    lines: list[str] = []
    for name in pkg_names:
        version = get_version(name)
        if version is None:
            # silently skip missing packages; you can add them later
            continue
        lines.append(f"{name}=={version}")
    return lines


def write_requirements_files(root: Path) -> None:
    """Write requirements.txt, requirements-experiments.txt, requirements-dev.txt."""
    # 1) Base runtime
    base_path = root / "requirements.txt"
    base_lines = [
        "# Auto-generated by scripts/update_requirements.py; do not edit by hand.",
        "# Base runtime dependencies for set-attention.",
        "",
        "# Use the PyTorch CUDA wheels (cu124) so GPU builds are installed by default.",
        "--extra-index-url https://download.pytorch.org/whl/cu124",
        "",
    ]
    base_lines += format_lines(RUNTIME_PKGS)
    base_text = "\n".join(base_lines) + "\n"
    base_path.write_text(base_text, encoding="utf-8")

    # 2) Experiments / training
    exp_path = root / "requirements-experiments.txt"
    exp_lines = [
        "# Auto-generated by scripts/update_requirements.py; do not edit by hand.",
        "# Extra dependencies required to run training / benchmark scripts.",
        "",
        "# Pull in base runtime deps (and the PyTorch cu124 index)",
        "-r requirements.txt",
        "",
    ]
    exp_lines += format_lines(EXPERIMENT_PKGS)
    exp_text = "\n".join(exp_lines) + "\n"
    exp_path.write_text(exp_text, encoding="utf-8")

    # 3) Dev tooling
    dev_path = root / "requirements-dev.txt"
    dev_lines = [
        "# Auto-generated by scripts/update_requirements.py; do not edit by hand.",
        "# Extra tooling for development (not needed just to run the library).",
        "",
        "# Everything needed for experiments:",
        "-r requirements-experiments.txt",
        "",
    ]
    dev_lines += format_lines(DEV_PKGS)
    dev_text = "\n".join(dev_lines) + "\n"
    dev_path.write_text(dev_text, encoding="utf-8")


# --- Entry point ------------------------------------------------------------


def main() -> None:
    repo_root = Path(__file__).resolve().parents[1]
    write_requirements_files(repo_root)
    print("Updated requirements.txt, requirements-experiments.txt, requirements-dev.txt")


if __name__ == "__main__":
    main()
